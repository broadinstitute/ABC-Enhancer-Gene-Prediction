import os
import pandas as pd
import hashlib
from snakemake.utils import min_version
min_version("7.0")

configfile: "config/config.yaml"
conda: "mamba"

NA_VAL = "None"
## load biosamples config file
BIOSAMPLES_CONFIG = pd.read_table(config["biosamplesTable"], na_values="").fillna(NA_VAL).set_index("biosample", drop=False)

## get list of biosamples
ALL_BIOSAMPLES = list(BIOSAMPLES_CONFIG.index.values)

def configure_tss_and_gene_files(biosamples_config):
	## get TSS and genefile names for each biosample 
	TSS_files = []
	gene_files = []
	for sample in ALL_BIOSAMPLES:
		tss_file = config['params_candidate']['genome_tss']
		gene_file = config['params_neighborhoods']['genes']
		if biosamples_config.loc[sample, "alt_TSS"] != "None":
			tss_file = biosamples_config.loc[sample, 'alt_TSS']
		if biosamples_config.loc[sample, "alt_genes"] != "None":
			gene_file = biosamples_config.loc[sample, 'alt_genes']
		TSS_files.append(tss_file)
		gene_files.append(gene_file)
					
	biosamples_config["TSS"] = TSS_files
	biosamples_config["genes"] = gene_files

def configure_hic_hashes(biosamples_config):
	"""
	Create a Map[hash(hic_dir), (hic_dir, hic_type, hic_gamma, hic_scale)]
	This is done so that we don't recompute hic powerlaw fit
	when multiple biosamples have the same hic_info
	"""
	hic_hashes = {}
	hic_pairs = biosamples_config[["HiC_dir", "HiC_type", "HiC_gamma", "HiC_scale"]].drop_duplicates()	
	for row in hic_pairs.values:
		hic_dir = row[0]
		if not hic_dir:
			# Map only contains values with hic_directories
			continue
		hic_hashes[get_hic_dir_hash(row)] = row
	return hic_hashes

def get_hic_dir_hash(hic_info_row):
	return hashlib.sha1(str(hic_info_row).encode()).hexdigest()[:8]

def get_hic_powerlaw_fit_dir(wildcards):
	"""
	If HiC is provided, we store the fit in the HiC hash folder. Otherwise
	we store under the biosamples folder
	"""
	row = BIOSAMPLES_CONFIG.loc[wildcards.biosample, ["HiC_dir", "HiC_type", "HiC_gamma", "HiC_scale"]].values
	hic_dir = row[0]
	if hic_dir != NA_VAL:
		return os.path.join(RESULTS_DIR, "HiC_Powerlaw", get_hic_dir_hash(row))
	else:
		return os.path.join(RESULTS_DIR, "HiC_Powerlaw", wildcards.biosample)

def get_hic_powerlaw_fit_file(wildcards):
	return os.path.join(get_hic_powerlaw_fit_dir(wildcards), "hic.powerlaw.tsv")

configure_tss_and_gene_files(BIOSAMPLES_CONFIG)
HiC_HASHES = configure_hic_hashes(BIOSAMPLES_CONFIG)
RESULTS_DIR = config['predictions_results_dir']

def get_accessibility_file(wildcards):
	default_accessibility_feature = BIOSAMPLES_CONFIG.loc[wildcards.biosample, 'default_accessibility_feature']
	return BIOSAMPLES_CONFIG.loc[wildcards.biosample, default_accessibility_feature]

## overall rule to run pipeline
rule all:
	input:
		allPutative = expand(
			os.path.join(RESULTS_DIR, "{biosample}", "Predictions", "EnhancerPredictionsAllPutative.txt.gz"), biosample=ALL_BIOSAMPLES
		),
		enhPredictions = expand(
			os.path.join(RESULTS_DIR, "{biosample}", "Predictions", "EnhancerPredictions.csv"), biosample=ALL_BIOSAMPLES
		),
		allPred = os.path.join(RESULTS_DIR,"AllPredictions.txt.gz"),
		metricsDirectory = expand(os.path.join(RESULTS_DIR, "{biosample}", "Metrics", "QCSummary.p"), biosample=ALL_BIOSAMPLES)

	
## call macs2 -- if multiple accessibility inputs for one biosample, will aggregate into one output
rule call_macs_peaks: 
	input:
		accessibility = get_accessibility_file
	params:
		pval = config['params_macs']['pval'],
		out_dir = config["predictions_results_dir"]
	conda:
		"envs/abcenv.yml"
	output: 
		narrowPeak = os.path.join(RESULTS_DIR, "{biosample}", "Peaks", "macs2_peaks.narrowPeak")
	shell: 
		""" 
		macs2 callpeak -f AUTO -g hs -p {params.pval} -n macs2 --call-summits --outdir {params.out_dir}/{wildcards.biosample}/Peaks -t {input.accessibility}
		"""

## sort narrowPeaks
rule sort_narrowpeaks:
	input:
		narrowPeak = os.path.join(RESULTS_DIR, "{biosample}", "Peaks", "macs2_peaks.narrowPeak")
	params:
		chrom_sizes = config['params_candidate']['chrom_sizes']
	conda:
		"envs/abcenv.yml"
	output:
		narrowPeakSorted = os.path.join(RESULTS_DIR, "{biosample}", "Peaks", "macs2_peaks.narrowPeak.sorted")
	shell:
		"""
		# intersect first to remove alternate chromosomes
		bedtools intersect -u -a {input.narrowPeak} -b {params.chrom_sizes}.bed | \
		bedtools sort -faidx {params.chrom_sizes} -i stdin > {output.narrowPeakSorted}
		"""

## call candidate regions
rule call_candidate_regions:
	input:
		narrowPeak = os.path.join(RESULTS_DIR, "{biosample}", "Peaks", "macs2_peaks.narrowPeak.sorted"),
	params:
		accessibility = get_accessibility_file,
		TSS = lambda wildcards: BIOSAMPLES_CONFIG.loc[wildcards.biosample, 'TSS'],
		chrom_sizes = config['params_candidate']['chrom_sizes'],
		regions_blocklist = config['params_candidate']['regions_blocklist'],
		peakExtendFromSummit = config['params_candidate']['peakExtendFromSummit'],
		nStrongestPeak = config['params_candidate']['nStrongestPeaks'],
		threads = 10,
		output_dir = RESULTS_DIR
	conda:
		"envs/abcenv.yml"
	output: 
		candidateRegions = os.path.join(RESULTS_DIR, "{biosample}", "Peaks", "macs2_peaks.narrowPeak.sorted.candidateRegions.bed")
	shell: 
		"""
		python workflow/scripts/makeCandidateRegions.py \
			--narrowPeak {input.narrowPeak}\
			--bam {params.accessibility} \
			--outDir {params.output_dir}/{wildcards.biosample}/Peaks \
			--chrom_sizes {params.chrom_sizes} \
			--regions_blocklist {params.regions_blocklist} \
			--regions_includelist {params.TSS} \
			--peakExtendFromSummit {params.peakExtendFromSummit} \
			--nStrongestPeak {params.nStrongestPeak}
		"""

## call neighborhoods
rule call_neighborhoods:
	input:		
		candidateRegions = os.path.join(RESULTS_DIR, "{biosample}", "Peaks", "macs2_peaks.narrowPeak.sorted.candidateRegions.bed"),
	params:
		DHS = lambda wildcards: BIOSAMPLES_CONFIG.loc[wildcards.biosample, 'DHS'] if not BIOSAMPLES_CONFIG.loc[wildcards.biosample, 'DHS']=='None' else '',
		ATAC = lambda wildcards: BIOSAMPLES_CONFIG.loc[wildcards.biosample, 'ATAC'] if not BIOSAMPLES_CONFIG.loc[wildcards.biosample, 'ATAC']=='None' else '',
		default = lambda wildcards: BIOSAMPLES_CONFIG.loc[wildcards.biosample, 'default_accessibility_feature'],
		H3K27ac = lambda wildcards: BIOSAMPLES_CONFIG.loc[wildcards.biosample, 'H3K27ac'] if not BIOSAMPLES_CONFIG.loc[wildcards.biosample, 'H3K27ac']=='None' else '',
		genes = lambda wildcards: BIOSAMPLES_CONFIG.loc[wildcards.biosample, 'genes'],
		ubiquitous_genes = config['params_neighborhoods']['ubiquitous_genes'],
		chrom_sizes = config['params_candidate']['chrom_sizes'],
		qnorm = config['params_neighborhoods']['qnorm'],
	conda:
		"envs/abcenv.yml"
	output: 
		enhList = os.path.join(RESULTS_DIR, "{biosample}", "Neighborhoods", "EnhancerList.txt"),
		geneList = os.path.join(RESULTS_DIR, "{biosample}", "Neighborhoods", "GeneList.txt"),
		neighborhoodDirectory = directory(os.path.join(RESULTS_DIR, "{biosample}", "Neighborhoods")),
	shell:
		"""
		# get sorted & unique gene list
		# intersect first to remove alternate chromosomes
		bedtools intersect -u -a {params.genes} -b {params.chrom_sizes}.bed | \
		bedtools sort -faidx {params.chrom_sizes} -i stdin | \
		uniq > {params.genes}.sorted.uniq
						
		python workflow/scripts/run.neighborhoods.py \
			--candidate_enhancer_regions {input.candidateRegions} \
			--DHS {params.DHS} \
			--ATAC {params.ATAC} \
			--default_accessibility_feature {params.default} \
			--chrom_sizes {params.chrom_sizes} \
			--outdir {output.neighborhoodDirectory} \
			--genes {params.genes}.sorted.uniq \
			--ubiquitously_expressed_genes {params.ubiquitous_genes} \
			--qnorm {params.qnorm} \
			--H3K27ac {params.H3K27ac}
		"""

def get_write_powerlaw_params(wildcards) -> str:
	if wildcards.KEY in HiC_HASHES:
		hic_dir, hic_type, hic_gamma, hic_scale = HiC_HASHES[wildcards.KEY]
		return f"--hic_dir {hic_dir} --hic_type {hic_type} --hic_gamma {hic_gamma} --hic_scale {hic_scale}"
	else:
		# Otherwise, KEY is a biosample and there's no HiC directory associated
		hic_gamma = BIOSAMPLES_CONFIG.loc[wildcards.KEY, "HiC_gamma"]
		hic_scale = BIOSAMPLES_CONFIG.loc[wildcards.KEY, "HiC_scale"]
		# values here are validated in the script
		return f"--hic_gamma {hic_gamma} --hic_scale {hic_scale}"
	
rule write_powerlaw_params:
	params:
		params = get_write_powerlaw_params
	output:
		powerlaw_params_tsv = os.path.join(RESULTS_DIR, "HiC_Powerlaw", "{KEY}", "hic.powerlaw.tsv")
	shell:
		"""
		python workflow/scripts/write_powerlaw_params.py \
			{params.params} \
			--output_file {output.powerlaw_params_tsv}
		"""

def get_run_predictions_hic_params(wildcards):
	hic_dir = BIOSAMPLES_CONFIG.loc[wildcards.biosample, "HiC_dir"]
	hic_type = BIOSAMPLES_CONFIG.loc[wildcards.biosample, "HiC_type"]
	if hic_dir == NA_VAL:
		return "--score_column powerlaw.Score"
	else:
		return f"--hic_dir {hic_dir} --hic_type {hic_type}"

### run predictions: takes in EnhancerList.txt and GeneList.txt generated from rule call_neighborhoods above and generates Enhancer-Gene Predictions and links
rule run_predictions:
	input:
		enhancers = os.path.join(RESULTS_DIR, "{biosample}", "Neighborhoods", "EnhancerList.txt"),
		genes = os.path.join(RESULTS_DIR, "{biosample}", "Neighborhoods", "GeneList.txt"),
		powerlaw_params_tsv = get_hic_powerlaw_fit_file
	params:
		cellType = lambda wildcards: wildcards.biosample, 
		output_dir = lambda wildcards: os.path.join(RESULTS_DIR, wildcards.biosample, "Predictions"),
		hic_params = get_run_predictions_hic_params,
		chrom_sizes = config['params_candidate']['chrom_sizes'],
		hic_resolution = config['params_predict']['hic_resolution'],  # TODO: Make this configurable in config-biosamples
		threshold = config['params_predict']['threshold'],
		flags = config['params_predict']['flags'],
	conda:
		"envs/abcenv.yml"
	output: 
		allPutative = os.path.join(RESULTS_DIR, "{biosample}", "Predictions", "EnhancerPredictionsAllPutative.txt.gz"),
		enhPredictions = os.path.join(RESULTS_DIR, "{biosample}", "Predictions", "EnhancerPredictions.csv"),
		enhPredictionsFull = os.path.join(RESULTS_DIR, "{biosample}", "Predictions", "EnhancerPredictionsFull.csv"),
	shell:
		"""
		python workflow/scripts/predict.py \
			--enhancers {input.enhancers} \
			--outdir {params.output_dir} \
			{params.hic_params} \
			--powerlaw_params_tsv {input.powerlaw_params_tsv} \
			--chrom_sizes {params.chrom_sizes} \
			--hic_resolution {params.hic_resolution} \
			--threshold {params.threshold} \
			--cellType {params.cellType} \
			--genes {input.genes} \
			{params.flags}
		"""

### generate AllPredictions file
rule make_all_predictions:
	input: 
		predLists = expand(os.path.join(RESULTS_DIR, "{biosample}", "Predictions", "EnhancerPredictions.csv"), biosample=ALL_BIOSAMPLES)
	params:
		output_dir = RESULTS_DIR
	conda:
		"envs/abcenv.yml"
	output:
		allPred = os.path.join(RESULTS_DIR,"AllPredictions.txt.gz")
	shell:
		"""			
		set +o pipefail;
		## make all predictions file 
		printf "chr\tstart\tend\tname\tTargetGene\tTargetGeneTSS\tCellType\tABC.Score\n" > {params.output_dir}/AllPredictions.txt
		for sample in {input.predLists}
		do
			cat $sample | sed 1d >> {params.output_dir}/AllPredictions.txt
		done
		gzip {params.output_dir}/AllPredictions.txt
		"""

rule gen_qc_plots:
	input: 
		candidateRegions = os.path.join(RESULTS_DIR, "{biosample}", "Peaks", "macs2_peaks.narrowPeak.sorted.candidateRegions.bed"),
		neighborhoodDirectory = directory(os.path.join(RESULTS_DIR, "{biosample}", "Neighborhoods")),
		enhPredictionsFull = os.path.join(RESULTS_DIR, "{biosample}", "Predictions", "EnhancerPredictionsFull.csv")
	params:
		output_dir = os.path.join(RESULTS_DIR, "{biosample}", "Metrics")
	conda:
		"envs/abcenv.yml"
	output:
		qc_summary = os.path.join(RESULTS_DIR, "{biosample}", "Metrics", "QCSummary.p")
	shell:
		"""
		python workflow/scripts/grabMetrics.py \
			--outdir {params.output_dir} \
			--macs_peaks {input.candidateRegions} \
			--neighborhood_outdir {input.neighborhoodDirectory} \
			--preds_file {input.enhPredictionsFull}
		"""
